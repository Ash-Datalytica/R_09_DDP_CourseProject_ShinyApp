}
mnist.loadFromBin <- function(mnistDirectory) {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
#reading the header:
readBin(f,'integer',n=1,size=4,endian='big') #magic number (2051)
ret$n = readBin(f,'integer',n=1,size=4,endian='big') #n rows (60000)
nrow = readBin(f,'integer',n=1,size=4,endian='big') #n pixel rows in one image (28)
ncol = readBin(f,'integer',n=1,size=4,endian='big') #n pixel columns in one image (28)
#print (ret$n); print (nrow);print (ncol);
#reading the data:
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F) #image pixel data
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
ret=list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
l = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
l
}
mnist.train <<- load_image_file(paste(mnistDirectory,'train-images.idx3-ubyte', sep=''))
mnist.test <<- load_image_file(paste(mnistDirectory,'t10k-images.idx3-ubyte', sep=''))
mnist.train$l <<- load_label_file(paste(mnistDirectory,'train-labels.idx1-ubyte',sep='')) #output decimal digit
mnist.test$l <<- load_label_file(paste(mnistDirectory,'t10k-labels.idx1-ubyte', sep = ''))
mnist.train$y <<- RSNNS::decodeClassLabels(mnist.train$l) #analogue to nnet::class.ind
mnist.test$y <<- RSNNS::decodeClassLabels(mnist.test$l) #output binary vector
#Set colnames for all used matrices
colnames(mnist.train$x)<<-paste0('x',1:ncol(mnist.train$x))
colnames(mnist.train$y)<<-paste0('y',(0:9))
colnames(mnist.test$x)<<-paste0('x',1:ncol(mnist.test$x))
colnames(mnist.test$y)<<-paste0('y',0:9)
}
mnist.show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
mnist.loadFromBin ("C:\Work\NNET_DIGITS\MNIST_DATA\UNZIP\")
mnist.loadFromBin ("C:\\Work\\NNET_DIGITS\\MNIST_DATA\\UNZIP\\")
train <- data.frame (mnist.train$x, label = mnist.train$l)
View (train)
train <- data.frame (label = mnist.train$l, mnist.train$x )
View (train)
train <- data.frame (label = as.factor(mnist.train$l), mnist.train$x )
str(train)
library (caret)
inTrain <- createDataPartition (y=train$label, p=0.01, list=FALSE)
training <- train[inTrain,]
validating <- train[-inTrain,]
dim (training); dim (testing)
dim (training); dim (validating)
nPredictors <- dim (training])[2]-1
nPredictors <- dim (training)[2]-1
system.time ({
nPredictors <- dim (training)[2]-1
modFit <- train (label ~ . ,
data=training[,-"classe"], method = "rf", prox=TRUE,
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
ceiling(nPredictors/2),
ceiling(nPredictors*2/3),
nPredictors
))
)
})
system.time ({
nPredictors <- dim (training)[2]-1
modFit <- train (label ~ . ,
data=training[,-"label"], method = "rf", prox=TRUE,
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
ceiling(nPredictors/2),
ceiling(nPredictors*2/3),
nPredictors
))
)
})
notUsed <- 1
nPredictors <- dim (training[,-notUsed])[2]
notUsed <- NULL
nPredictors <- dim (training[,-notUsed])[2]
notUsed <- NA
nPredictors <- dim (training[,-notUsed])[2]
notUsed <- ""
nPredictors <- dim (training[,-notUsed])[2] -1
nPredictors <- dim (training[,])[2] -1
system.time ({
nPredictors <- dim (training[,])[2] -1
modFit <- train (label ~ . ,
data=training[,], method = "rf", prox=TRUE,
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
ceiling(nPredictors/2),
ceiling(nPredictors*2/3),
nPredictors
))
)
})
stopCluster(cl) # Explicitly free up cores again.
library("doSNOW")
cl<-makeCluster(5) # Assign number of cores to use
registerDoSNOW(cl) # Register the cores.
system.time ({
nPredictors <- dim (training[,])[2] -1
modFit <- train (label ~ . ,
data=training[,], method = "rf", prox=TRUE,
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
ceiling(nPredictors/2),
ceiling(nPredictors*2/3),
nPredictors
))
)
})
modFit
confusionMatrix(predict (modFit, newdata = validating), validating$classe)
confusionMatrix(predict (modFit, newdata = validating), validating$label)
notUsedColumns <- nearZeroVar (training, saveMetrics=FALSE, uniqueCut = 0.05) #0.05%
names(training)[notUsedColumns]
system.time ({
nPredictors <- dim (training[,-notUsedColumns])[2] -1
modFit <- train (label ~ . ,
data=training[,-notUsedColumns], method = "rf", prox=TRUE,
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
ceiling(nPredictors/2),
ceiling(nPredictors*2/3),
nPredictors
))
)
})
modFit
#check Accuracy
confusionMatrix(predict (modFit, newdata = validating), validating$label)
save (modFit, file= "TrainedModel.RData" )
save (modFit, file= "TrainedModel.RData", compress = "gzip" )
save (modFit, file= "TrainedModel.RData", compress = TRUE )
stopCluster(cl) # Explicitly free up cores again.
mdl <- load ("TrainedModel.RData")
remove(mdl)
mdl <- load ("TrainedModel.RData")
mdl
mdl$modFit
load ("TrainedModel.RData")
remove(modFit)
load ("TrainedModel.RData")
modFit
testing <- data.frame (label = as.factor(mnist.test$l), mnist.test$x )
predict (modFit, newdata = testing[,1:10])
predict (modFit, newdata = testing[1:10,])
save (list = c("modFit", "testing"), file= "TrainedModel.RData", compress = TRUE )
remove(modFit); remove(testing)
load ("TrainedModel.RData")
predict (modFit, newdata = testing[1:10,])
data.frame(label = testing[1:10,], prediction = predict (modFit, newdata = testing[1:10,]))
str(testing)
data.frame(label = testing[1:10,1], prediction = predict (modFit, newdata = testing[1:10,]))
data.frame(label = testing[caseNumber,1], prediction = predict (modFit, newdata = testing[caseNumber,]))
caseNumber <- 100:110
data.frame(label = testing[caseNumber,1], prediction = predict (modFit, newdata = testing[caseNumber,]))
res <- data.frame(label = testing[caseNumber,1], prediction = predict (modFit, newdata = testing[caseNumber,]))
res <- data.frame(label = testing[caseNumber,1], prediction = predict (modFit, newdata = testing[caseNumber,]))
res
#Example: mnist.show_digit (train$x[20000,])
mnist.show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
mnist.show_digit(testing[caseNumber,-1])
mnist.show_digit(testing[10,-1])
str(testing[10,-1])
as.vector(testing[10,-1])
mnist.show_digit(as.vector(testing[10,-1]))
mnist.show_digit(as.vector(test$x[10,]))
mnist.show_digit(as.vector(mnist.test$x[10,]))
mnist.show_digit(mnist.test$x[10,])
class(mnist.test$x[10,])
class(as.vector(testing[10,-1]))
class(as.integer(testing[10,-1]))
mnist.show_digit(as.integer(testing[10,-1]))
mnist.show_digit(as.integer(testing[10:11,-1]))
res <- data.frame(label = testing[caseNumber,1], prediction = predict (modFit, newdata = testing[caseNumber,]))
mnist.show_digit(as.integer(testing[casenumber,-1]))
mnist.show_digit(as.integer(testing[caseNumber,-1]))
caseNumber <- 100
res <- data.frame(label = testing[caseNumber,1], prediction = predict (modFit, newdata = testing[caseNumber,]))
res
mnist.show_digit(as.integer(testing[caseNumber,-1]))
shiny::runApp()
shiny::runApp()
shiny::runApp()
preProc <- preProcess(training[,-notUsedColumns], method="pca", thresh=0.95)
preProc
preProc <- preProcess(training[,-c (1,notUsedColumns)], method="pca", thresh=0.95)
preProc
trainingPC <- cbind(training$label, predict(preProc, training[,-notUsedColumns]))
trainingPC <- cbind(training$label, predict(preProc, training[,-c(1,notUsedColumns)]))
validatingPC <- cbind(validating$label, predict (preProc, validating[,-c(1,notUsedColumns)]))
nPredictors <- dim (trainingPC[,])[2] -1
## with preProc (PCA)
system.time ({
nPredictors <- dim (trainingPC[,])[2] -1
modFit <- train (label ~ . ,
data=trainingPC, method = "rf", prox=TRUE,
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
ceiling(nPredictors/2),
ceiling(nPredictors*2/3),
nPredictors
))
)
})
modFit
preProc <- preProcess(training[,-c (1,notUsedColumns)], method="pca", thresh=0.95)
preProc
trainingPC <- cbind(training$label, predict(preProc, training[,-c(1,notUsedColumns)]))
validatingPC <- cbind(validating$label, predict (preProc, validating[,-c(1,notUsedColumns)]))
View(trainingPC)
trainingPC <- cbind(label = training$label, predict(preProc, training[,-c(1,notUsedColumns)]))
validatingPC <- cbind(label = validating$label, predict (preProc, validating[,-c(1,notUsedColumns)]))
View(trainingPC)
system.time ({
nPredictors <- dim (trainingPC[,])[2] -1
modFit <- train (label ~ . ,
data=trainingPC, method = "rf", prox=TRUE,
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
ceiling(nPredictors/2),
ceiling(nPredictors*2/3),
nPredictors
))
)
})
modFit
stopCluster(cl) # Explicitly free up cores again.
cl<-makeCluster(5) # Assign number of cores to use
registerDoSNOW(cl) # Register the cores.
system.time ({
nPredictors <- dim (trainingPC[,])[2] -1
modFit <- train (label ~ . ,
data=trainingPC, method = "rf", prox=TRUE,
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
ceiling(nPredictors/2),
ceiling(nPredictors*2/3),
nPredictors
))
)
})
modFit
set.seed (1234)
inTrain <- createDataPartition (y=train$label, p=0.1, list=FALSE)
training <- train[inTrain,]
validating <- train[-inTrain,]
notUsedColumns <- nearZeroVar (training, saveMetrics=FALSE, uniqueCut = 0.05) #0.05%
preProc <- preProcess(training[,-c (1,notUsedColumns)], method="pca", thresh=0.95)
preProc
trainingPC <- cbind(label = training$label, predict(preProc, training[,-c(1,notUsedColumns)]))
validatingPC <- cbind(label = validating$label, predict (preProc, validating[,-c(1,notUsedColumns)]))
dim (training); dim (validating)
system.time ({
nPredictors <- dim (trainingPC[,])[2] -1
modFit <- train (label ~ . ,
data=trainingPC, method = "rf", prox=TRUE,
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
ceiling(nPredictors/2),
ceiling(nPredictors*2/3),
nPredictors
))
)
})
modFit
#check Accuracy
confusionMatrix(predict (modFit, newdata = validatingPC), validatingPC$label)
#nzv, pca .95, 158 predictors, 1%, 5 threads - 67 sec, mtry=13 (sqrt), acc=.88
2603/60
set.seed (1234)
inTrain <- createDataPartition (y=train$label, p=0.01, list=FALSE)
training <- train[inTrain,]
validating <- train[-inTrain,]
dim (training); dim (validating)
### Process features
#Exclude near zero variance variables, e.g. all values are NA's
notUsedColumns <- nearZeroVar (training, saveMetrics=FALSE, uniqueCut = 0.05) #0.05%
#names(training)[notUsedColumns]
preProc <- preProcess(training[,-c (1,notUsedColumns)], method="pca", thresh=0.95)
preProc
trainingPC <- cbind(label = training$label, predict(preProc, training[,-c(1,notUsedColumns)]))
validatingPC <- cbind(label = validating$label, predict (preProc, validating[,-c(1,notUsedColumns)]))
system.time ({
nPredictors <- dim (training[,-notUsedColumns])[2] -1
modFit <- train (label ~ . ,
data=training[,-notUsedColumns], method = "svmPoly",
trControl = trainControl (method="cv", number = 10, repeats = 10),
#                      tuneGrid=data.frame(mtry=c(
#                          ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
#                          ceiling(nPredictors/2),
#                          ceiling(nPredictors*2/3),
#                          nPredictors
#                      ))
)
})
modFit
#check Accuracy
confusionMatrix(predict (modFit, newdata = validating), validating$label)
system.time ({
nPredictors <- dim (training[,-notUsedColumns])[2] -1
modFit <- train (label ~ . ,
data=training[,-notUsedColumns], method = "svmPoly",
trControl = trainControl (method="cv", number = 10, repeats = 10)
#                      ,tuneGrid=data.frame(mtry=c(
#                          ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
#                          ceiling(nPredictors/2),
#                          ceiling(nPredictors*2/3),
#                          nPredictors
#                      ))
)
})
set.seed (1234)
inTrain <- createDataPartition (y=train$label, p=0.01, list=FALSE)
training <- train[inTrain,]
validating <- train[-inTrain,]
dim (training); dim (validating)
### Process features
#Exclude near zero variance variables, e.g. all values are NA's
notUsedColumns <- nearZeroVar (training, saveMetrics=FALSE, uniqueCut = 0.05) #0.05%
#names(training)[notUsedColumns]
preProc <- preProcess(training[,-c (1,notUsedColumns)], method="pca", thresh=0.95)
preProc
trainingPC <- cbind(label = training$label, predict(preProc, training[,-c(1,notUsedColumns)]))
validatingPC <- cbind(label = validating$label, predict (preProc, validating[,-c(1,notUsedColumns)]))
system.time ({
nPredictors <- dim (training[,-notUsedColumns])[2] -1
modFit <- train (label ~ . ,
data=training[,-notUsedColumns], method = "svmPoly",
trControl = trainControl (method="cv", number = 10, repeats = 10)
#                      ,tuneGrid=data.frame(mtry=c(
#                          ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
#                          ceiling(nPredictors/2),
#                          ceiling(nPredictors*2/3),
#                          nPredictors
#                      ))
)
})
modFit
#check Accuracy
confusionMatrix(predict (modFit, newdata = validating), validating$label)
stopCluster(cl) # Explicitly free up cores again.
cl<-makeCluster(5) # Assign number of cores to use
registerDoSNOW(cl) # Register the cores.
system.time ({
nPredictors <- dim (training[,-notUsedColumns])[2] -1
modFit <- train (label ~ . ,
data=training[,-notUsedColumns], method = "svmPoly",
trControl = trainControl (method="cv", number = 10, repeats = 10)
#                      ,tuneGrid=data.frame(mtry=c(
#                          ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
#                          ceiling(nPredictors/2),
#                          ceiling(nPredictors*2/3),
#                          nPredictors
#                      ))
)
})
modFit
confusionMatrix(predict (modFit, newdata = validating), validating$label)
system.time ({
nPredictors <- dim (training[,-notUsedColumns])[2] -1
modFit <- train (label ~ . ,
data=training[,-notUsedColumns], method = "mlpWeightDecay",
trControl = trainControl (method="cv", number = 10, repeats = 10)
#                      ,
#                      tuneGrid=data.frame(size=30,)
#                      ,tuneGrid=data.frame(mtry=c(
#                          ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
#                          ceiling(nPredictors/2),
#                          ceiling(nPredictors*2/3),
#                          nPredictors
#                      ))
)
})
modFit
#check Accuracy
confusionMatrix(predict (modFit, newdata = validating), validating$label)
946/60
caret::confusionMatrix(predict (modFit, newdata = validating), validating$label)
caret::confusionMatrix(predict (modFit, newdata = validating[1:1000,]), validating[1:1000,]$label)
caret::confusionMatrix(predict (modFit, newdata = validating[1:10,]), validating[1:10,]$label)
modFit
confusionMatrix(predict (modFit, newdata = validating[1:10,]), validating[1:10,]$label)
caret::confusionMatrix(predict (modFit, newdata = validating[1:10,]), validating[1:10,]$label)
caret::confusionMatrix(predict (modFit, newdata = validating[1:100,]), validating[1:100,]$label)
system.time ({
nPredictors <- dim (training[,-notUsedColumns])[2] -1
modFit <- caret::train (label ~ . ,
data=training[,-notUsedColumns], method = "mlpWeightDecay",
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(size=30, .decay = c(0,1e-4, 1e-3, 1e-2))
#                      ,tuneGrid=data.frame(mtry=c(
#                          ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
#                          ceiling(nPredictors/2),
#                          ceiling(nPredictors*2/3),
#                          nPredictors
#                      ))
)
})
modFit
system.time ({
nPredictors <- dim (training[,-notUsedColumns])[2] -1
modFit <- caret::train (label ~ . ,
data=training[,-notUsedColumns], method = "mlpWeightDecay",
trControl = trainControl (method="cv", number = 10, repeats = 10),
tuneGrid=data.frame(size=30, decay = c(0,1e-4, 1e-3, 1e-2))
#                      ,tuneGrid=data.frame(mtry=c(
#                          ceiling(sqrt(nPredictors)), ceiling(nPredictors/3),
#                          ceiling(nPredictors/2),
#                          ceiling(nPredictors*2/3),
#                          nPredictors
#                      ))
)
})
=728/60
728/60
modFit
caret::confusionMatrix(predict (modFit, newdata = validating[1:100,]), validating[1:100,]$label)
set.seed (1234)
inTrain <- createDataPartition (y=train$label, p=0.05, list=FALSE)
training <- train[inTrain,]
validating <- train[-inTrain,]
dim (training); dim (validating)
### Process features
#Exclude near zero variance variables, e.g. all values are NA's
notUsedColumns <- nearZeroVar (training, saveMetrics=FALSE, uniqueCut = 0.05) #0.05%
#names(training)[notUsedColumns]
preProc <- preProcess(training[,-c (1,notUsedColumns)], method="pca", thresh=0.95)
preProc
trainingPC <- cbind(label = training$label, predict(preProc, training[,-c(1,notUsedColumns)]))
validatingPC <- cbind(label = validating$label, predict (preProc, validating[,-c(1,notUsedColumns)]))
system.time ({
nPredictors <- dim (training[,-notUsedColumns])[2] -1
modFit <- caret::train (label ~ . ,
data=training[,-notUsedColumns], method = "mlpWeightDecay",
trControl = trainControl (method="cv", number = 10, repeats = 10),
#tuneGrid=data.frame(size=30, decay = c(0,1e-4, 1e-3, 1e-2))
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors))
#                          , ceiling(nPredictors/3),
#                          ceiling(nPredictors/2),
#                          ceiling(nPredictors*2/3),
#                          nPredictors
))
)
})
modFit
system.time ({
nPredictors <- dim (training[,-notUsedColumns])[2] -1
modFit <- caret::train (label ~ . ,
data=training[,-notUsedColumns], method = "rf",
trControl = trainControl (method="cv", number = 10, repeats = 10),
#tuneGrid=data.frame(size=30, decay = c(0,1e-4, 1e-3, 1e-2))
tuneGrid=data.frame(mtry=c(
ceiling(sqrt(nPredictors))
#                          , ceiling(nPredictors/3),
#                          ceiling(nPredictors/2),
#                          ceiling(nPredictors*2/3),
#                          nPredictors
))
)
})
modFit
#check Accuracy
caret::confusionMatrix(predict (modFit, newdata = validating), validating$label)
452/60
save (list = c("modFit", "testing"), file= "TrainedModel.RData", compress = TRUE )
stopCluster(cl) # Explicitly free up cores again.
remove(modFit); remove(testing)
load ("TrainedModel.RData")
caseNumber <- 100
res <- data.frame(label = testing[caseNumber,1], prediction = predict (modFit, newdata = testing[caseNumber,]))
res
mnist.show_digit(as.integer(testing[caseNumber,-1]))
shiny::runApp()
save (list = c("modFit", "testing"), file= "TrainedModel.RDA", compress = TRUE )
remove(modFit); remove(testing)
load ("TrainedModel.RDA")
shiny::runApp()
shiny::runApp()
shiny::runApp()
library (caret)
